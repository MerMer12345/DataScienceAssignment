{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This file will clean the rows of the datasets which have too many null values",
   "id": "a8b36f6691594b45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Any rows with a Sample_Size of under 50 and any row without a Data_Value will be removed. ",
   "id": "fd9faab9a124b802"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T18:05:58.370394Z",
     "start_time": "2024-10-27T18:05:57.084895Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv')\n",
    "output_file = 'filtered_file.csv'\n",
    "filtered_df = df[(df['Sample_Size'] > 50) & (df['Data_Value'] != 0)]\n",
    "\n",
    "filtered_df.to_csv(output_file, index=False)"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T18:05:58.669948Z",
     "start_time": "2024-10-27T18:05:58.375391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = pd.read_csv('filtered_file.csv')\n",
    "df2_sample = df2[df2['Sample_Size'] <= 50]\n",
    "num_rows = len(df2_sample)\n",
    "print('Number of Rows with a sample size of 0:', num_rows)\n",
    "print('Number of Rows in total',len(df2))"
   ],
   "id": "220be0455e0bb100",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows with a sample size of 0: 0\n",
      "Number of Rows in total 93403\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T18:05:59.012399Z",
     "start_time": "2024-10-27T18:05:58.960264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "null_counts = df2.isnull().sum().sort_values()\n",
    "\n",
    "print(\"Columns with the least null values:\")\n",
    "print(null_counts)"
   ],
   "id": "f52fffff6e2e6fe2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the least null values:\n",
      "YearStart                         0\n",
      "YearEnd                           0\n",
      "LocationAbbr                      0\n",
      "LocationDesc                      0\n",
      "Datasource                        0\n",
      "Class                             0\n",
      "Topic                             0\n",
      "Question                          0\n",
      "Data_Value_Type                   0\n",
      "Data_Value                        0\n",
      "Data_Value_Alt                    0\n",
      "High_Confidence_Limit             0\n",
      "Low_Confidence_Limit              0\n",
      "StratificationCategory1           0\n",
      "Stratification1                   0\n",
      "Sample_Size                       0\n",
      "StratificationCategoryId1         0\n",
      "QuestionID                        0\n",
      "TopicID                           0\n",
      "LocationID                        0\n",
      "DataValueTypeID                   0\n",
      "ClassID                           0\n",
      "StratificationID1                 0\n",
      "GeoLocation                    1929\n",
      "Data_Value_Unit               13646\n",
      "Income                        67620\n",
      "Age(years)                    71301\n",
      "Race/Ethnicity                73673\n",
      "Education                     78667\n",
      "Gender                        86035\n",
      "Total                         89719\n",
      "Data_Value_Footnote_Symbol    93403\n",
      "Data_Value_Footnote           93403\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Large amount of null values is because of the way the dataset is designed, each row is only meant to give information about one particualr topic, decided by the Stratification Category, \n",
    "\n",
    "for example Stratification Category \"Age\" would contain information about the Age of the participants of the survey, and the Stratification would be 55-64. \n",
    "\n",
    "Any Data marked with \"total\" in the Total column will be moved to its own file and removed from the main dataset \n",
    "\n",
    "Data_Value_Footnote_Symbol and Data_Value_Footnote will be dropped, because they are not necessary for our purposes. \n",
    "\n",
    "The empty Geolocation values could be filled with the geolocation of the state in which the information was collected, which might falsify the results to some degree, but since the exact location is not relevant to our goals, this column will be dropped. \n",
    "\n",
    "YearStart and YearEnd will be combined into one column Year, as it is always the same\n",
    "\n",
    "Data_Value_Unit, Data_Value_Type and DataValueTypeID will be dropped, as all are just used to say that it is in percent, which we know.\n",
    "Data_Value_Unit may also give information about the Year of the row, but we already have the YearStart and YearEnd columns for that.\n",
    "DataValueTypeID gives a lookup identifier for the DataValueType, which we do not need.\n",
    "\n",
    " "
   ],
   "id": "9a17f009c1abf127"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T18:06:00.036143Z",
     "start_time": "2024-10-27T18:05:59.016401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = df2.drop('Data_Value_Footnote', axis=1)\n",
    "df2 = df2.drop('Data_Value_Footnote_Symbol', axis=1)\n",
    "df2.drop('YearEnd', axis=1)\n",
    "df2.drop('Data_Value_Unit', axis=1)\n",
    "df2.drop('Data_Value_Type', axis=1)\n",
    "df2.drop('DataValueTypeID', axis=1)\n",
    "df2 = df2.drop('GeoLocation', axis=1)\n",
    "\n",
    "\n",
    "df2.to_csv(output_file, index=False)"
   ],
   "id": "c255e207eeba37aa",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T18:06:01.005227Z",
     "start_time": "2024-10-27T18:06:00.180741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_Obesity = 'Data/Obesity/Obesity_file.csv'\n",
    "df_Obesity = df2[df2['Question'].isin(['Percent of adults aged 18 years and older who have obesity'])]\n",
    "df_Obesity.to_csv(output_Obesity, index=False)\n",
    "print('Number Obesity', len(df_Obesity))\n",
    "\n",
    "output_overweight = 'Data/Overweight_file.csv'\n",
    "df_overweight = df2[df2['Question'].isin(['Percent of adults aged 18 years and older who have an overweight classification'])]\n",
    "df_overweight.to_csv(output_overweight, index=False)\n",
    "print('Number Overweight', len(df_overweight))\n",
    "\n",
    "output_nosport = 'Data/Nosport_file.csv'\n",
    "df_nosport = df2[df2['Question'].isin(['Percent of adults who engage in no leisure-time physical activity'])]\n",
    "df_nosport.to_csv(output_nosport, index=False)\n",
    "print('Number Nosport', len(df_nosport))\n",
    "\n",
    "output_muscle ='Data/Muscle_file.csv'\n",
    "df_muscle = df2[df2['Question'].isin(['Percent of adults who engage in muscle-strengthening activities on 2 or more days a week '])]\n",
    "df_muscle.to_csv(output_muscle, index=False)\n",
    "print('Number Muscle', len(df_muscle))\n",
    "\n",
    "output_150752 = 'Data/150752_file.csv'\n",
    "df_150752 = df2[df2['Question'].isin(['Percent of adults who achieve at least 150 minutes a week of moderate-intensity aerobic physical activity or 75 minutes a week of vigorous-intensity aerobic physical activity and engage in muscle-strengthening activities on 2 or more days a week'])]\n",
    "df_150752.to_csv(output_150752, index=False)\n",
    "print('Number 150752', len(df_150752))\n",
    "\n",
    "output_300150 = 'Data/300150_file.csv'\n",
    "df_300150 = df2[df2['Question'].isin(['Percent of adults who achieve at least 300 minutes a week of moderate-intensity aerobic physical activity or 150 minutes a week of vigorous-intensity aerobic activity (or an equivalent combination)'])]\n",
    "df_300150.to_csv(output_300150, index=False)\n",
    "print('Number 300150', len(df_300150))\n",
    "\n",
    "output_15075 = 'Data/15075_file.csv'\n",
    "df_15075 = df2[df2['Question'].isin(['Percent of adults who achieve at least 150 minutes a week of moderate-intensity aerobic physical activity or 75 minutes a week of vigorous-intensity aerobic activity (or an equivalent combination)'])]\n",
    "df_15075.to_csv(output_15075, index=False)\n",
    "print('Number 15075', len(df_15075))\n",
    "\n",
    "output_fruity = 'Data/Fruity_file.csv'\n",
    "df_fruity = df2[df2['Question'].isin(['Percent of adults who report consuming fruit less than one time daily'])]\n",
    "df_fruity.to_csv(output_fruity, index=False)\n",
    "print('Number Fruity', len(df_fruity))\n",
    "\n",
    "output_veggis = 'Data/Veggis_file.csv'\n",
    "df_veggis = df2[df2['Question'].isin(['Percent of adults who report consuming vegetables less than one time dail'])]\n",
    "df_veggis.to_csv(output_veggis, index=False)\n",
    "print('Number Vegis', len(df_veggis))\n",
    "\n"
   ],
   "id": "745895d21a3e73c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Obesity 17673\n",
      "Number Overweight 17673\n",
      "Number Nosport 17727\n",
      "Number Muscle 0\n",
      "Number 150752 8034\n",
      "Number 300150 8034\n",
      "Number 15075 8044\n",
      "Number Fruity 4075\n",
      "Number Vegis 0\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Obesity seperated by Stratification Category + Total",
   "id": "1974c47302dc1802"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T18:06:01.329209Z",
     "start_time": "2024-10-27T18:06:01.158268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_Obesity_Total = df_Obesity[df_Obesity['Total'] == 'Total']\n",
    "output_Obesity_Total = 'Data/Obesity/Obesity_file_total.csv'\n",
    "df_Obesity_Total.to_csv(output_Obesity_Total, index=False)\n",
    "\n",
    "\n",
    "df_Obesity_Total = df_Obesity[df_Obesity['StratificationCategory1'] == 'Race/Ethnicity']\n",
    "output_Obesity = 'Data/Obesity/Obesity_file_RaceEthnicity.csv'\n",
    "df_Obesity_Total.to_csv(output_Obesity, index=False)\n",
    "\n",
    "df_Obesity_Total = df_Obesity[df_Obesity['StratificationCategory1'] == 'Income']\n",
    "output_Obesity = 'Data/Obesity/Obesity_file_Income.csv'\n",
    "df_Obesity_Total.to_csv(output_Obesity, index=False)\n",
    "\n",
    "df_Obesity_Total = df_Obesity[df_Obesity['StratificationCategory1'] == 'Age (years)']\n",
    "output_Obesity = 'Data/Obesity/Obesity_file_Age.csv'\n",
    "df_Obesity_Total.to_csv(output_Obesity, index=False)\n",
    "\n",
    "df_Obesity_Total = df_Obesity[df_Obesity['StratificationCategory1'] == 'Education']\n",
    "output_Obesity = 'Data/Obesity/Obesity_file_Education.csv'\n",
    "df_Obesity_Total.to_csv(output_Obesity, index=False)\n",
    "\n",
    "df_Obesity_Total = df_Obesity[df_Obesity['StratificationCategory1'] == 'Gender']\n",
    "output_Obesity = 'Data/Obesity/Obesity_file_Gender.csv'\n",
    "df_Obesity_Total.to_csv(output_Obesity, index=False)\n"
   ],
   "id": "996d85d9c543fbbc",
   "outputs": [],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
